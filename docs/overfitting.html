<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Overfitting | STA6257 Cross Validation</title>
  <meta name="description" content="Overfitting | STA6257 Cross Validation">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 2 The pool of tears | STA6257 Cross Validation" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 The pool of tears | STA6257 Cross Validation" />
  
  
  

<meta name="author" content="Mary Tarabocchia, Jason Heiserman, Daniel Bohorquez">


<meta name="date" content="2022-10-20">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="overfitting.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Cross Validation Research Project</a></li>

<li class="divider"></li>
<li><a href="index.html#index" id="Introduction"><span class="toc-section-number"><b>1</b></span> Introduction</a></li>
<ol>
<li><a href="definition.html#definition" id="Definition"><span class="toc-section-number"><b>1.1</b></span> Definition</a></li>
<li><a href="overfitting.html#overfitting" id="Overfitting"><span class="toc-section-number"><b>1.2</b></span> Overfitting</a></li>
</ol>
<li><a href="cross-validation.html#cross-validation" id="Types of Cross-Validation"><span class="toc-section-number"><b>2</b></span> Types of Cross-Validation</a></li>
<ol>
<li><a href="k-fold.html#k-fold" id="K-Fold Cross-Validation"><span class="toc-section-number"><b>2.1</b></span> K-Fold Cross-Validation</a></li>
<li><a href="stratified.html#stratified" id="Stratified K-Fold Cross-Validation"><span class="toc-section-number"><b>2.2</b></span> Stratified K-Fold Cross-Validation</a></li>
<li><a href="holdout-method.html#holdout-method" id="Holdout Method"><span class="toc-section-number"><b>2.3</b></span> Holdout Method</a></li>
<li><a href="leave-one-out.html#leave-one-out" id="Leave-One-Out Cross-Validation"><span class="toc-section-number"><b>2.4</b></span> Leave-One-Out Cross-Validation</a></li>
<li><a href="leave-p-out.html#leave-p-out" id="Leave-P-Out Cross-Validation"><span class="toc-section-number"><b>2.5</b></span> Leave-P-Out Cross-Validation</a></li>
<li><a href="monte-carlo.html#monte-carlo" id="Monte Carlo Cross-Validation"><span class="toc-section-number"><b>2.6</b></span> Monte Carlo Cross-Validation</a></li>
</ol>
<li><a href="limitations.html#limitations" id="Limitations of Cross-Validation"><span class="toc-section-number"><b>3</b></span> Limitations of Cross-Validation</a></li>
<li><a href="methods.html#methods" id="Methods"><span class="toc-section-number"><b>4</b></span> Methods</a></li>
<ol>
<li><a href="data.html#data" id="Data"><span class="toc-section-number"><b>4.1</b></span> Data</a></li>
<li><a href="statistical-methods.html#statistical-method" id="Statistical-Method"><span class="toc-section-number"><b>4.2</b></span> Statistical-Method</a></li>
<ol>
<li><a href="kfold-results.html#analysis-results" id="Analysis-Results"><span class="toc-section-number"><b>4.2.1</b></span> K-Fold Testing & Results</a></li>
<li><a href="holdout-results.html#analysis-results" id="Analysis-Results"><span class="toc-section-number"><b>4.2.2</b></span> Holdout Testing & Results</a></li>
<li><a href="leave-one-results.html#analysis-results" id="Analysis-Results"><span class="toc-section-number"><b>4.4.3</b></span> Leave-One-Out Testing & Results</a></li>
</ol>
<li><a href="conclusion.html#references" id="Conclusion"><span class="toc-section-number"><b>5</b></span> Conclusion</a></li>
<li><a href="references.html#references" id="References"><span class="toc-section-number"><b>6</b></span> References</a></li>
<li><a href="code.html#code" id="code"><span class="toc-section-number"><b></b></span> Code</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STA6257 Cross Validation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="overfitting" class="section level1" number="2">
<h2><span class="header-section-number">1.2 Overfitting</span></h2>
<p class=MsoNormal>&nbsp;</p>
  
<p class=MsoNormal>Overfitting is a &quot;phenomenon where fitting the observed
facts (data) well no longer indicates that we will get a decent out-of-sample
error, and may actually lead to the opposite effect.&quot; (Abu-Mostafa, 2012)
Overfitting occurs when noise in the data &quot;has misled the data.&quot;
(Abu-Mostafa, 2012) “Noise” in this context means data points which do not
represent the true properties of the data, but only exist due to random chance.
(Lever, 2016) Overfitted models “tend to memorize all the data, including
unavoidable noise on the training set, instead of learning the discipline
hidden behind the data.” (Ying, 2019)  </p>

<p class=MsoNormal>Another cause of overfitting is “when the training set is
too small or is not representative of the data as a whole, the noises have a greater
chance of being learned, and later act as a basis of predictions.” (Ying, 2019)
Overfitted models “tend to memorize all the data, including unavoidable noise
on the training set, instead of learning the discipline hidden behind the
data.” (Ying, 2019)</p>
  
<p class=MsoNormal> &quot;When a model is too complex, it overfits the data. This happens because the model 
   works too hard to find patterns in the training data that are just caused by random chance.&quot; 
   (Lau, 2020) &quot;When a model is too simple, it underfits the data.  Underfitting occurs when the 
   true relationship between the explanatory variables and the response variable is simpler than it is.&quot;
   (Lau, 2020)</p>
  
<p class=MsoNormal> Analyzing the graphs below, the model labeled Underfit has many data points are misclassified.  
  On the other hand, the model labeled Overfit has allowed noise to affect the results.  The model in the middle 
  maintains a balance: it captures the structural constancy in the data to form the model, while resisting the noise 
  and refusing to let it bend its decision boundary.</p>
  
<p class=MsoNormal><img width=846 height=284 id="Picture 8"
src="images/image008.png"
alt="Diagram&#10;&#10;Description automatically generated" class="center"></p>

<p class=MsoNormal>Additionally, there is a tradeoff between bias and variance
that one must consider. “When a model is too complex, it overfits the data.
This happens because the model works too hard to find patterns in the training
data that are just caused by random chance.” (Lau, 2020) “When a model is too
simple, it underfits the data.  Underfitting occurs when the true relationship
between the explanatory variables and the response variable is simpler than it
is.” (Lau, 2020) In the graph below, the horizontal axis is epoch, and the
vertical axis is error, the blue line is the training error and the red line is
the validation error.  If we stop learning before the yellow triangle, it’s
underfitting. If we stop after the yellow triangle, we get overfitting.</p>

<p class=MsoNormal><img width=446 height=284 id="Picture 1"
src="images/image001.png"
alt="Diagram&#10;&#10;Description automatically generated" class="center"></p>

<p class=MsoNormal>Another “cure” for overfitting is regularization. (Abu-Mostafa, 2012) Regularization means “restricting a model
to avoid overfitting by shrinking the coefficient estimates to zero.” (Abu-Mostafa, 2012) When a model becomes
too complicated, it tends to take all the features into consideration, even though some of them have very
limited effect on the final output. (Ling, 2019) Regularization avoids overfitting by adding a penalty to the
model’s loss function. (Ling, 2019) Ying proposes pruning the model “to reduce classification complexity by
eliminating less meaningful, or irrelevant data.” One can implement pre-pruning by deleting conditions and rules from the 
model during the learning process or post-pruning by removing conditions and rules from the
  model that were generated during the learning phase. (Ying, 2019) </p>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="definition.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="cross-validation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dquez88/STA6257-Cross-Validation-Research-Project/edit/master/02-tears.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
